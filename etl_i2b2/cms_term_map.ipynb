{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMS to PCORNet Terminology Mapping\n",
    "\n",
    "The naive code building approach in `cms_pd.CMSRIFUpload.pivot_valtype` results in\n",
    "demographic codes from such as\n",
    "\n",
    " - `BENE_SEX_IDENT_CD:2` for Female and\n",
    " - `BENE_RACE_CD:1` for White\n",
    "\n",
    "The codes come from\n",
    "[Data Dictionaries - Chronic Conditions Data Warehouse](https://www.ccwdata.org/web/guest/data-dictionaries).\n",
    "\n",
    "On the other hand, the GROUSE i2b2 uses and ontology based on\n",
    "[PCORNet CDM](http://www.pcornet.org/pcornet-common-data-model/), which uses\n",
    "\n",
    " - F=Female\n",
    " - 05=White"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCORNet \"parseable\" Common Data Model\n",
    "\n",
    "The codes from the PCORNet are published in a nice tidy spreadsheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dict(pandas=pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.request import build_opener as build_web_access\n",
    "\n",
    "from cms_code_table import Cache\n",
    "\n",
    "\n",
    "class PCORNetCDM(Cache):\n",
    "    [v3dot1] = [\n",
    "        ('PCORnet Common Data Model v3.1 Parseable Spreadsheet Format',\n",
    "         'http://www.pcornet.org/wp-content/uploads/2017/01/2017-01-06-PCORnet-Common-Data-Model-v3dot1-parseable.xlsx',\n",
    "         'f085b975ec5e59bef3bf505aaa3107e3f4e12e4c')\n",
    "    ]\n",
    "cdm_cache = PCORNetCDM.make(Path('cache'), build_web_access())\n",
    "\n",
    "pcornet_cdm = pd.read_excel(str(cdm_cache[cdm_cache.v3dot1]), sheetname=None)\n",
    "\n",
    "pcornet_cdm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcornet_value = pcornet_cdm['VALUESETS'].rename(\n",
    "    columns={n: n.lower() for n in pcornet_cdm['VALUESETS'].columns})\n",
    "pcornet_value[pcornet_value.field_name.isin(['SEX', 'RACE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcornet_value['descriptor'] = pcornet_value.valueset_item_descriptor.str.replace('[^=]+=', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMS Data Dictionaries\n",
    "\n",
    "The data dictionaries from CMS are published in PDF, so recovering the structure is a bit more involved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cms_code_table import Cache\n",
    "\n",
    "\n",
    "class CMSDataDictionaries(Cache):\n",
    "    [mbsf_abcd, ffs_claims] = [\n",
    "        ('Master Beneficiary Summary - Base (A/B/C/D) Codebook',\n",
    "         'https://www.ccwdata.org/documents/10280/19022436/codebook-mbsf-abcd.pdf',\n",
    "         '2f7fce7c849e011d125a8487833e6cdd4ca7ced7'),\n",
    "        ('Medicare Fee-For-Service Claims Codebook',\n",
    "         'https://www.ccwdata.org/documents/10280/19022436/codebook-ffs-claims.pdf',\n",
    "         '1e5d2e3300d8d6dab2e005ebd369d3aca02162c7')\n",
    "    ]\n",
    "cms_cache = CMSDataDictionaries.make(Path('cache'), build_web_access())\n",
    "mbsf_abcd_codebook = cms_cache[cms_cache.mbsf_abcd]\n",
    "mbsf_abcd_codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then convert to text using [poppler](http://poppler.freedesktop.org/) tools..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pdftotext -layout cache/codebook-mbsf-abcd.pdf\n",
    "\n",
    "# Package: poppler-utils\n",
    "# Original-Maintainer: Loic Minier <lool@dooz.org>\n",
    "# Architecture: amd64\n",
    "# Version: 0.41.0-0ubuntu1\n",
    "# SHA1: 03e35d9c79455b01cffcbc635219bdb665067740\n",
    "# Description-en: PDF utilities (based on Poppler)\n",
    "\n",
    "def text_file(path,\n",
    "              suffix='.txt'):\n",
    "    df = pd.DataFrame({\n",
    "        'line': [line.strip('\\f\\n') for line in\n",
    "                 path.with_suffix('.txt').open().readlines()]})\n",
    "    return df\n",
    "\n",
    "codebook_text = text_file(mbsf_abcd_codebook)\n",
    "codebook_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's prune the TOC and page footers, leaving just the body:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toc_dots(line,\n",
    "             pattern=r'.*\\.\\.\\.'):\n",
    "    return line.str.match(pattern)\n",
    "\n",
    "codebook_text[toc_dots(codebook_text.line)].iloc[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def footer_ix(line,\n",
    "              patterns=[\n",
    "        r'^\\s+\\^ Back to TOC \\^',\n",
    "        r'^CMS Chronic Conditions Data Warehouse \\(CCW\\)',\n",
    "        r'^May 2017 â€“ Version 1.0  \\s*  Page \\d+ of \\d+$'],\n",
    "              footer_extra=[]):\n",
    "    is_footer = pd.Series(False, index=line.index)\n",
    "    for footer_pattern in patterns + footer_extra:\n",
    "        is_footer = is_footer | line.str.match(footer_pattern)\n",
    "    return is_footer\n",
    "\n",
    "codebook_text[footer_ix(codebook_text.line)][1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_body(text,\n",
    "              footer_extra=[]):\n",
    "    is_toc = toc_dots(text.line)\n",
    "    text['is_body'] = (~footer_ix(text.line, footer_extra=footer_extra) &\n",
    "                       (text.index > is_toc[is_toc].index.max()))\n",
    "    return text\n",
    "\n",
    "codebook_text = with_body(codebook_text, footer_extra=[r'^Master Beneficiary Summary File \\(MBSF\\) with'])\n",
    "codebook_text[codebook_text.is_body & (codebook_text.line > '')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a section for each variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_variable(text,\n",
    "                  pattern=r'^   \\s*([A-Z_0-9]+)$'):\n",
    "    text['variable'] = text.line.str.extract(r'^   \\s*([A-Z_0-9]+)$', expand=False)\n",
    "    text.loc[~text.is_body, 'variable'] = None\n",
    "    return text\n",
    "\n",
    "codebook_text = with_variable(codebook_text)\n",
    "codebook_text[codebook_text.line.str.strip() == codebook_text.variable].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dictionary describes each variable and nominal value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lhs_rhs(line):\n",
    "    \"\"\"\n",
    "    e.g. SHORT NAME: B_MO_CNT\n",
    "    also rhs with empty lhs from comment, description\n",
    "    \"\"\"\n",
    "    df = line.str.extract(\n",
    "         r'^(?:(?P<lhs>[A-Z\\(\\)]+(?: [A-Z]+)*):\\s*|            \\s*)(?P<rhs>.*)', expand=True)\n",
    "    df.rhs = df.rhs.fillna('')\n",
    "    return df\n",
    "\n",
    "\n",
    "extract_lhs_rhs(pd.Series('''\n",
    "SOURCE:        NCH\n",
    "FILE(S):\n",
    "VALUES:        A = Assigned claim\n",
    "               N = Non-assigned claim\n",
    "DESCRIPTION: The 1st diagnosis code used to identify the patient's reason for the Hospital Outpatient\n",
    "visit.\n",
    "'''.split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stderr\n",
    "\n",
    "\n",
    "def extract_valuesets(line):\n",
    "    return line.str.extract(\n",
    "        r' (?P<valueset_item>\\S+) = (?P<descriptor>.*)', expand=True)\n",
    "\n",
    "\n",
    "def para_agg(df, text_cols, index, columns, values,\n",
    "             sep='\\n'):\n",
    "    return (\n",
    "        df[df.lhs.isin(text_cols)]\n",
    "        .groupby([index, columns])[values]\n",
    "        .apply(lambda values: sep.join(txt or '' for txt in values))\n",
    "        .reset_index()\n",
    "        .pivot(index=index, columns=columns, values=values))\n",
    "\n",
    "\n",
    "def find_pivot_dups(df, index, columns, values):\n",
    "    x = df[[index, columns]].sort_values([index, columns])\n",
    "    return x[x.duplicated()]\n",
    "\n",
    "\n",
    "def codebook_parts(codebook_text):\n",
    "    codebook = pd.concat([codebook_text,\n",
    "                          extract_lhs_rhs(codebook_text.line),\n",
    "                          extract_valuesets(codebook_text.line)], axis=1)\n",
    "\n",
    "    codebook.loc[~codebook.variable.isnull(), 'lhs'] = 'variable'\n",
    "    codebook.lhs = codebook.lhs.fillna(method='pad')\n",
    "    codebook.variable = codebook.variable.fillna(method='pad')\n",
    "\n",
    "    codebook = codebook[codebook.is_body & (codebook.line > '')]\n",
    "    codebook_values = codebook[~codebook.valueset_item.isnull()][['variable', 'valueset_item', 'descriptor']]\n",
    "\n",
    "    para_cols = ['LABEL', 'COMMENT', 'DESCRIPTION']\n",
    "    to_pivot = codebook[~codebook.lhs.isin(\n",
    "        ['variable', 'VALUES', 'CODE VALUES'] + para_cols)]\n",
    "    oops = find_pivot_dups(to_pivot, index='variable', columns='lhs', values='rhs')\n",
    "    if len(oops) > 0:\n",
    "        print(oops, file=stderr)\n",
    "        raise ValueError()\n",
    "    simple_cols = to_pivot.pivot(index='variable', columns='lhs', values='rhs')\n",
    "    codebook_variables = pd.concat(\n",
    "        [simple_cols,\n",
    "         para_agg(codebook, para_cols, 'variable', 'lhs', 'rhs')], axis=1)\n",
    "    return codebook_variables, codebook_values\n",
    "\n",
    "codebook_variables, codebook_values = codebook_parts(codebook_text)\n",
    "\n",
    "codebook_variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_values[codebook_values.variable == 'SEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_values[codebook_values.variable == 'RACE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_by_descriptor(fields, codebook_values, pcornet_value):\n",
    "    lhs = codebook_values.rename(columns={'variable': 'field_name'})\n",
    "    rhs = pcornet_value.drop(['valueset_item_descriptor'], axis=1)\n",
    "    map = pd.merge(\n",
    "        lhs[codebook_values.variable.isin(fields)],\n",
    "        rhs[pcornet_value.field_name.isin(fields)],\n",
    "        on='descriptor', how='outer', suffixes=('_cms', '_pcornet')\n",
    "    )\n",
    "    return map\n",
    "\n",
    "dem_terms_to_map = map_by_descriptor(\n",
    "    ['SEX', 'RACE', 'HISPANIC'], codebook_values, pcornet_value).set_index(\n",
    "    'valueset_item_order').sort_index()[['table_name', 'field_name_pcornet',\n",
    "                                         'valueset_item_pcornet', 'descriptor', 'valueset_item_cms', 'field_name_cms']]\n",
    "# dem_terms_to_map.to_csv('cms_pcornet_mapping.csv')\n",
    "dem_terms_to_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms_pcornet_mapping = pd.read_csv('cms_pcornet_mapping.csv', dtype=dict(valueset_item_cms=str))\n",
    "cms_pcornet_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns of an i2b2 metadata table:\n",
    "meta_cols = [col.lower() for col in '''\n",
    "C_HLEVEL\n",
    "C_FULLNAME\n",
    "C_NAME\n",
    "C_SYNONYM_CD\n",
    "C_VISUALATTRIBUTES\n",
    "C_TOTALNUM\n",
    "C_BASECODE\n",
    "C_METADATAXML\n",
    "C_FACTTABLECOLUMN\n",
    "C_TABLENAME\n",
    "C_COLUMNNAME\n",
    "C_COLUMNDATATYPE\n",
    "C_OPERATOR\n",
    "C_DIMCODE\n",
    "C_COMMENT\n",
    "C_TOOLTIP\n",
    "M_APPLIED_PATH\n",
    "UPDATE_DATE\n",
    "DOWNLOAD_DATE\n",
    "IMPORT_DATE\n",
    "SOURCESYSTEM_CD\n",
    "VALUETYPE_CD\n",
    "M_EXCLUSION_CD\n",
    "C_PATH\n",
    "C_SYMBOL\n",
    "'''.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def as_i2b2_meta(info, update_date,\n",
    "                 sourcesystem_cd=__name__): # TODO?\n",
    "    info = info[~info.field_name_cms.isnull()]\n",
    "    c_hlevel = 3\n",
    "    c_fullname = info.apply(lambda item: (r'\\PCORI\\{table}\\{field}\\{value}' + '\\\\').format(\n",
    "        table=item.table_name,\n",
    "        field=item.field_name_pcornet,\n",
    "        value=item.valueset_item_pcornet), axis=1)\n",
    "    c_basecode = info.apply(lambda item: '{scheme}:{value}'.format(\n",
    "        scheme=item.field_name_cms,\n",
    "        value=item.valueset_item_cms), axis=1)\n",
    "\n",
    "    leaf_active = 'LA'\n",
    "    c_tooltip = info.field_name_cms + ' ' + info.descriptor  # hmm...\n",
    "\n",
    "    meta = pd.DataFrame.from_items([\n",
    "        ('c_hlevel', c_hlevel),\n",
    "        ('c_fullname', c_fullname),\n",
    "        ('c_name', info.descriptor),\n",
    "        ('c_synonym_cd', 'N'),\n",
    "        ('c_visualattributes', leaf_active),\n",
    "        ('c_totalnum', np.nan),\n",
    "        ('c_basecode', c_basecode),\n",
    "        ('c_metadataxml', None),\n",
    "        ('c_facttablecolumn', 'concept_cd'),\n",
    "        ('c_tablename', 'concept_dimension'),\n",
    "        ('c_columnname', 'concept_path'),\n",
    "        ('c_columndatatype', 'T'),\n",
    "        ('c_operator', 'like'),\n",
    "        ('c_dimcode', c_fullname),\n",
    "        ('c_comment', None),\n",
    "        ('c_tooltip', c_tooltip),\n",
    "        ('m_applied_path', '@'),\n",
    "        ('update_date', update_date),\n",
    "        ('download_date', update_date),\n",
    "        ('import_date', update_date),\n",
    "        ('sourcesystem_cd', sourcesystem_cd),\n",
    "        ('valuetype_cd', None),\n",
    "        ('m_exclusion_cd', None),\n",
    "        ('c_path', None),\n",
    "        ('c_symbol', None),\n",
    "        ('pcori_basecode', info.valueset_item_pcornet)]).set_index(\n",
    "            # The table is typically indexed uniquely on c_fullname, but\n",
    "            # we include c_hlevel in the index to preserve column order\n",
    "            ['c_hlevel', 'c_fullname'])\n",
    "    #TODO: fix for index cols assert list(meta.columns) == meta_cols\n",
    "    return meta\n",
    "\n",
    "cms_pcornet_terms = as_i2b2_meta(cms_pcornet_mapping, datetime.now(), sourcesystem_cd='grouse.kumc.edu')\n",
    "cms_pcornet_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISSUE: ambient. should use pathlib and pass file handle rather than string\n",
    "cms_pcornet_terms.to_csv('cms_pcornet_terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need them in the concept dimension too...\n",
    "def as_concept_dimension(meta, upload_id):\n",
    "    cd = pd.DataFrame.from_items([\n",
    "        ('concept_path', meta.c_dimcode),\n",
    "        ('concept_cd', meta.c_basecode),\n",
    "        ('name_char', meta.c_name),\n",
    "        ('concept_blob', None),\n",
    "        ('update_date', meta.update_date.max()),\n",
    "        ('download_date', meta.download_date),\n",
    "        ('import_date', meta.import_date.max()),\n",
    "        ('sourcesystem_cd', meta.sourcesystem_cd),\n",
    "        ('upload_id', upload_id)\n",
    "    ]).set_index('concept_path')\n",
    "    return cd\n",
    "\n",
    "as_concept_dimension(cms_pcornet_terms, upload_id=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB Access via Luigi Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reset_luigi_config(path):\n",
    "    '''Reach into luigi guts and reset the config.\n",
    "    \n",
    "    Don't ask.'''\n",
    "    import luigi\n",
    "    cls = luigi.configuration.LuigiConfigParser\n",
    "    cls._instance = None  # KLUDGE\n",
    "    cls._config_paths = [str(path)]\n",
    "    return cls.instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this first so that luigi's configuration logging is captured.\n",
    "from sys import stderr\n",
    "from os import environ\n",
    "from getpass import getpass\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "from cms_code_table import log_to_stream\n",
    "\n",
    "log = log_to_stream(logging.getLogger(), stderr)\n",
    "log.info('We aim to log non-trivial IO (esp. DB access)')\n",
    "\n",
    "\n",
    "# This has to go before importing etl_tasks\n",
    "_reset_luigi_config(Path('luigi-sgrouse.cfg'))\n",
    "\n",
    "\n",
    "from cms_etl import CMSExtract\n",
    "\n",
    "cms_rif_task = CMSExtract()\n",
    "cms_rif_task._fix_password(environ, getpass)\n",
    "\n",
    "with cms_rif_task.connection() as logged_conn:\n",
    "    [_] = logged_conn.execute('select global_name from global_name').fetchone()\n",
    "\n",
    "_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save terms in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sqla\n",
    "\n",
    "def obj_string(df,\n",
    "               clobs=[],\n",
    "               pad=4):\n",
    "    '''avoid CLOBs'''\n",
    "    df = df.reset_index()\n",
    "    obj_cols = [col for (col, ty) in df.dtypes.items()\n",
    "                if ty.kind == 'O' and col not in clobs]\n",
    "    return {col: sqla.types.String(np.nanmax([df[col].str.len().max() + pad, pad]))\n",
    "            for col in obj_cols}\n",
    "\n",
    "\n",
    "with cms_rif_task.connection('save terms') as lc:\n",
    "    # presumes it exists; can we do without it?\n",
    "    # lc.execute('truncate table cms_pcornet_terms')\n",
    "\n",
    "    cms_pcornet_terms.to_sql(\n",
    "        'cms_pcornet_terms', con=lc._conn, if_exists='replace',\n",
    "        dtype=obj_string(cms_pcornet_terms, clobs=['c_metadataxml', 'c_comment']))\n",
    "    cd = as_concept_dimension(cms_pcornet_terms,\n",
    "                              upload_id=-1)  # TODO?\n",
    "    cd.to_sql(\n",
    "        'cms_pcornet_terms_cdim', con=lc._conn, if_exists='replace',\n",
    "        dtype=obj_string(cd, clobs=['concept_blob']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medicare Fee-For-Service Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pdftotext -layout cache/codebook-ffs-claims.pdf\n",
    "\n",
    "claims_text = text_file(cms_cache[cms_cache.ffs_claims])\n",
    "\n",
    "def fix_empty_rhs(text,\n",
    "                  target_lhs='VALUES:'):\n",
    "    ix = text.line[text.line == target_lhs].index.min()\n",
    "    print(text.line.loc[ix:ix + 1], file=stderr)\n",
    "    text.loc[ix, 'line'] = ''\n",
    "    no_lhs = text.line[ix + 1]\n",
    "    text.loc[ix + 1, 'line'] = target_lhs + no_lhs[len(target_lhs):]\n",
    "    print(text.line.loc[ix:ix + 1], file=stderr)\n",
    "    return text\n",
    "\n",
    "claims_text = with_body(claims_text,\n",
    "          footer_extra=[r'Medicare FFS Claims \\(Version K\\) Codebook',\n",
    "                        r'^Variable Details',\n",
    "                        r'^This section of the Codebook contains',\n",
    "                        r'^Service Claims \\(Version K\\)',\n",
    "                        r'^and use of the variables.'])\n",
    "claims_text.line = fix_empty_rhs(claims_text)\n",
    "claims_text = with_variable(claims_text)\n",
    "claims_text[~claims_text.variable.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_variables, claims_values = codebook_parts(claims_text)\n",
    "claims_variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_variables[claims_variables['LONG NAME'] == 'prf_physn_npi'.upper()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(claims_variables[claims_variables['LONG NAME'] == 'prf_physn_upin'.upper()].DESCRIPTION[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "last update date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, v in claims_variables[claims_variables['TYPE'] == 'DATE'].iterrows():\n",
    "    #print(v)\n",
    "    print()\n",
    "    print(v['LONG NAME'])\n",
    "    print(v.DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(claims_variables[claims_variables['LONG NAME'] == 'line_last_expns_dt'.upper()].DESCRIPTION[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
